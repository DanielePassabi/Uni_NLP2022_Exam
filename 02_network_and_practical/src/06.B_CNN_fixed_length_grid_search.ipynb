{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Introduction to ML for NLP [Network + Practical]**\n",
    "\n",
    "### **CNN**\n",
    "\n",
    "We have seen in notebook 6.A that we can correctly train a CNN in each language.\n",
    "\n",
    "We now have to tune the model, and store the best results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Libraries**\n",
    "\n",
    "We import the necessary libraries for the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Libraries Imported\n"
     ]
    }
   ],
   "source": [
    "# general\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "# pytorch\n",
    "import torch\n",
    "\n",
    "# reload libs\n",
    "import importlib\n",
    "\n",
    "# custom imports\n",
    "import utility.models_pytorch as CustomPytorchModule\n",
    "\n",
    "print(\"> Libraries Imported\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Setup**\n",
    "\n",
    "- We set the device to *cuda*\n",
    "- We import the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(\"> Device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>celex_id</th>\n",
       "      <th>labels</th>\n",
       "      <th>labels_new</th>\n",
       "      <th>text_en</th>\n",
       "      <th>text_de</th>\n",
       "      <th>text_it</th>\n",
       "      <th>text_pl</th>\n",
       "      <th>text_sv</th>\n",
       "      <th>text_en_enc</th>\n",
       "      <th>text_de_enc</th>\n",
       "      <th>text_it_enc</th>\n",
       "      <th>text_pl_enc</th>\n",
       "      <th>text_sv_enc</th>\n",
       "      <th>set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32010D0395</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>commission decision of december on state aid c...</td>\n",
       "      <td>beschluss der kommission vom dezember uber die...</td>\n",
       "      <td>decisione della commissione del dicembre conce...</td>\n",
       "      <td>decyzja komisji z dnia grudnia r w sprawie pom...</td>\n",
       "      <td>kommissionens beslut av den december om det st...</td>\n",
       "      <td>[[2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, ...</td>\n",
       "      <td>[[2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, ...</td>\n",
       "      <td>[[2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, ...</td>\n",
       "      <td>[[2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, ...</td>\n",
       "      <td>[[2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, ...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32012R0453</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>commission implementing regulation eu no of ma...</td>\n",
       "      <td>durchfuhrungsverordnung eu nr der kommission v...</td>\n",
       "      <td>regolamento di esecuzione ue n della commissio...</td>\n",
       "      <td>rozporzadzenie wykonawcze komisji ue nr z dnia...</td>\n",
       "      <td>kommissionens genomforandeforordning eu nr av ...</td>\n",
       "      <td>[[2, 1275, 1276, 29, 100, 4, 743, 1277, 15, 12...</td>\n",
       "      <td>[[1302, 33, 1303, 3, 4, 5, 807, 15, 1304, 3, 6...</td>\n",
       "      <td>[[453, 10, 1422, 38, 14, 3, 4, 5, 990, 1423, 1...</td>\n",
       "      <td>[[1753, 1754, 3, 34, 24, 4, 5, 829, 7, 1755, 9...</td>\n",
       "      <td>[[2, 1239, 33, 23, 4, 5, 806, 7, 774, 4, 132, ...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32012D0043</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>commission implementing decision of january au...</td>\n",
       "      <td>durchfuhrungsbeschluss der kommission vom janu...</td>\n",
       "      <td>decisione di esecuzione della commissione del ...</td>\n",
       "      <td>decyzja wykonawcza komisji z dnia stycznia r u...</td>\n",
       "      <td>kommissionens genomforandebeslut av den januar...</td>\n",
       "      <td>[[2, 1275, 3, 4, 1310, 1311, 15, 1015, 4, 1312...</td>\n",
       "      <td>[[1344, 3, 4, 5, 1345, 15, 1346, 74, 1347, 134...</td>\n",
       "      <td>[[2, 10, 1422, 3, 4, 5, 1454, 245, 1455, 24, 1...</td>\n",
       "      <td>[[2, 1791, 3, 4, 5, 1792, 7, 1, 1793, 1794, 65...</td>\n",
       "      <td>[[2, 1279, 4, 5, 1280, 7, 1281, 19, 1282, 1283...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     celex_id  labels  labels_new  \\\n",
       "0  32010D0395       2           0   \n",
       "1  32012R0453       2           0   \n",
       "2  32012D0043       2           0   \n",
       "\n",
       "                                             text_en  \\\n",
       "0  commission decision of december on state aid c...   \n",
       "1  commission implementing regulation eu no of ma...   \n",
       "2  commission implementing decision of january au...   \n",
       "\n",
       "                                             text_de  \\\n",
       "0  beschluss der kommission vom dezember uber die...   \n",
       "1  durchfuhrungsverordnung eu nr der kommission v...   \n",
       "2  durchfuhrungsbeschluss der kommission vom janu...   \n",
       "\n",
       "                                             text_it  \\\n",
       "0  decisione della commissione del dicembre conce...   \n",
       "1  regolamento di esecuzione ue n della commissio...   \n",
       "2  decisione di esecuzione della commissione del ...   \n",
       "\n",
       "                                             text_pl  \\\n",
       "0  decyzja komisji z dnia grudnia r w sprawie pom...   \n",
       "1  rozporzadzenie wykonawcze komisji ue nr z dnia...   \n",
       "2  decyzja wykonawcza komisji z dnia stycznia r u...   \n",
       "\n",
       "                                             text_sv  \\\n",
       "0  kommissionens beslut av den december om det st...   \n",
       "1  kommissionens genomforandeforordning eu nr av ...   \n",
       "2  kommissionens genomforandebeslut av den januar...   \n",
       "\n",
       "                                         text_en_enc  \\\n",
       "0  [[2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, ...   \n",
       "1  [[2, 1275, 1276, 29, 100, 4, 743, 1277, 15, 12...   \n",
       "2  [[2, 1275, 3, 4, 1310, 1311, 15, 1015, 4, 1312...   \n",
       "\n",
       "                                         text_de_enc  \\\n",
       "0  [[2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, ...   \n",
       "1  [[1302, 33, 1303, 3, 4, 5, 807, 15, 1304, 3, 6...   \n",
       "2  [[1344, 3, 4, 5, 1345, 15, 1346, 74, 1347, 134...   \n",
       "\n",
       "                                         text_it_enc  \\\n",
       "0  [[2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, ...   \n",
       "1  [[453, 10, 1422, 38, 14, 3, 4, 5, 990, 1423, 1...   \n",
       "2  [[2, 10, 1422, 3, 4, 5, 1454, 245, 1455, 24, 1...   \n",
       "\n",
       "                                         text_pl_enc  \\\n",
       "0  [[2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, ...   \n",
       "1  [[1753, 1754, 3, 34, 24, 4, 5, 829, 7, 1755, 9...   \n",
       "2  [[2, 1791, 3, 4, 5, 1792, 7, 1, 1793, 1794, 65...   \n",
       "\n",
       "                                         text_sv_enc    set  \n",
       "0  [[2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, ...  train  \n",
       "1  [[2, 1239, 33, 23, 4, 5, 806, 7, 774, 4, 132, ...  train  \n",
       "2  [[2, 1279, 4, 5, 1280, 7, 1281, 19, 1282, 1283...  train  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe = pd.read_pickle(\"data/3_multi_eurlex_encoded.pkl\")\n",
    "dataframe.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Create a Grid Search for Fine Tuning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we setup the needed parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters setup\n",
    "\n",
    "COUNTS_EN = 3506\n",
    "COUNTS_DE = 4216\n",
    "COUNTS_IT = 4180\n",
    "COUNTS_PL = 5255\n",
    "COUNTS_SV = 4010\n",
    "\n",
    "LEARNING_RATE_LIST = [0.001, 0.0001]\n",
    "EMBEDDING_DIM_LIST = [1024, 2048]\n",
    "KERNEL_SIZE_LIST = [3,5,7]\n",
    "STRIDE_LIST = [1,3]\n",
    "PADDING_LIST = [1,3]\n",
    "DROPOUT_P_LIST = [0.0, 0.1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we execute a grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Parameters imported for CNN_fixed\n",
      "> Dataset correctly divided in training set, validation set and test set\n",
      "> Created Pytorch datasets and dataloaders\n",
      "> Initialization required 0.152 seconds\n",
      "==================================================================================\n",
      "> Training Started\n",
      "  - Total Epochs: 50\n",
      "==================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "> Epoch 1:   0%|          | 0/60 [00:02<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Daniele\\Documents\\Programmazione\\Github\\Uni_NLP2022_Exam\\02_network_and_practical\\src\\06.B_CNN_fixed_length_grid_search.ipynb Cell 11'\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Daniele/Documents/Programmazione/Github/Uni_NLP2022_Exam/02_network_and_practical/src/06.B_CNN_fixed_length_grid_search.ipynb#ch0000010?line=15'>16</a>\u001b[0m CNN_MODEL \u001b[39m=\u001b[39m PYTORCH_MODEL(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Daniele/Documents/Programmazione/Github/Uni_NLP2022_Exam/02_network_and_practical/src/06.B_CNN_fixed_length_grid_search.ipynb#ch0000010?line=16'>17</a>\u001b[0m \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Daniele/Documents/Programmazione/Github/Uni_NLP2022_Exam/02_network_and_practical/src/06.B_CNN_fixed_length_grid_search.ipynb#ch0000010?line=17'>18</a>\u001b[0m     \u001b[39m# set model and text language\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Daniele/Documents/Programmazione/Github/Uni_NLP2022_Exam/02_network_and_practical/src/06.B_CNN_fixed_length_grid_search.ipynb#ch0000010?line=37'>38</a>\u001b[0m     dropout_p       \u001b[39m=\u001b[39m DROPOUT_P,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Daniele/Documents/Programmazione/Github/Uni_NLP2022_Exam/02_network_and_practical/src/06.B_CNN_fixed_length_grid_search.ipynb#ch0000010?line=38'>39</a>\u001b[0m )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Daniele/Documents/Programmazione/Github/Uni_NLP2022_Exam/02_network_and_practical/src/06.B_CNN_fixed_length_grid_search.ipynb#ch0000010?line=41'>42</a>\u001b[0m \u001b[39m# train the model\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Daniele/Documents/Programmazione/Github/Uni_NLP2022_Exam/02_network_and_practical/src/06.B_CNN_fixed_length_grid_search.ipynb#ch0000010?line=42'>43</a>\u001b[0m CNN_MODEL\u001b[39m.\u001b[39;49mtrain_model()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Daniele/Documents/Programmazione/Github/Uni_NLP2022_Exam/02_network_and_practical/src/06.B_CNN_fixed_length_grid_search.ipynb#ch0000010?line=44'>45</a>\u001b[0m iteration\u001b[39m+\u001b[39m\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Daniele\\Documents\\Programmazione\\Github\\Uni_NLP2022_Exam\\02_network_and_practical\\src\\utility\\models_pytorch.py:235\u001b[0m, in \u001b[0;36mPytorchModel.train_model\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Daniele/Documents/Programmazione/Github/Uni_NLP2022_Exam/02_network_and_practical/src/utility/models_pytorch.py?line=231'>232</a>\u001b[0m y \u001b[39m=\u001b[39m y\u001b[39m.\u001b[39mtype(torch\u001b[39m.\u001b[39mFloatTensor)\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mDEVICE)\n\u001b[0;32m    <a href='file:///c%3A/Users/Daniele/Documents/Programmazione/Github/Uni_NLP2022_Exam/02_network_and_practical/src/utility/models_pytorch.py?line=233'>234</a>\u001b[0m \u001b[39m# Feed the model\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/Daniele/Documents/Programmazione/Github/Uni_NLP2022_Exam/02_network_and_practical/src/utility/models_pytorch.py?line=234'>235</a>\u001b[0m y_pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mMODEL(x, l)\n\u001b[0;32m    <a href='file:///c%3A/Users/Daniele/Documents/Programmazione/Github/Uni_NLP2022_Exam/02_network_and_practical/src/utility/models_pytorch.py?line=236'>237</a>\u001b[0m \u001b[39m# obtain loss\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Daniele/Documents/Programmazione/Github/Uni_NLP2022_Exam/02_network_and_practical/src/utility/models_pytorch.py?line=237'>238</a>\u001b[0m loss \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mcross_entropy(y_pred, y\u001b[39m.\u001b[39mlong())       \n",
      "File \u001b[1;32md:\\Programmi\\Anaconda\\envs\\NLP_2022\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///d%3A/Programmi/Anaconda/envs/NLP_2022/lib/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   <a href='file:///d%3A/Programmi/Anaconda/envs/NLP_2022/lib/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   <a href='file:///d%3A/Programmi/Anaconda/envs/NLP_2022/lib/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   <a href='file:///d%3A/Programmi/Anaconda/envs/NLP_2022/lib/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> <a href='file:///d%3A/Programmi/Anaconda/envs/NLP_2022/lib/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   <a href='file:///d%3A/Programmi/Anaconda/envs/NLP_2022/lib/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   <a href='file:///d%3A/Programmi/Anaconda/envs/NLP_2022/lib/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\Daniele\\Documents\\Programmazione\\Github\\Uni_NLP2022_Exam\\02_network_and_practical\\src\\utility\\models_pytorch.py:638\u001b[0m, in \u001b[0;36mCNN_fixed_len.forward\u001b[1;34m(self, x, l)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Daniele/Documents/Programmazione/Github/Uni_NLP2022_Exam/02_network_and_practical/src/utility/models_pytorch.py?line=634'>635</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_pool(x)\n\u001b[0;32m    <a href='file:///c%3A/Users/Daniele/Documents/Programmazione/Github/Uni_NLP2022_Exam/02_network_and_practical/src/utility/models_pytorch.py?line=636'>637</a>\u001b[0m \u001b[39m# Pass through fully connected layer\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/Daniele/Documents/Programmazione/Github/Uni_NLP2022_Exam/02_network_and_practical/src/utility/models_pytorch.py?line=637'>638</a>\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlinear(x)\n\u001b[0;32m    <a href='file:///c%3A/Users/Daniele/Documents/Programmazione/Github/Uni_NLP2022_Exam/02_network_and_practical/src/utility/models_pytorch.py?line=639'>640</a>\u001b[0m \u001b[39m# apply dropout\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Daniele/Documents/Programmazione/Github/Uni_NLP2022_Exam/02_network_and_practical/src/utility/models_pytorch.py?line=640'>641</a>\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(out)\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mDEVICE)\n",
      "File \u001b[1;32md:\\Programmi\\Anaconda\\envs\\NLP_2022\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///d%3A/Programmi/Anaconda/envs/NLP_2022/lib/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   <a href='file:///d%3A/Programmi/Anaconda/envs/NLP_2022/lib/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   <a href='file:///d%3A/Programmi/Anaconda/envs/NLP_2022/lib/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   <a href='file:///d%3A/Programmi/Anaconda/envs/NLP_2022/lib/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> <a href='file:///d%3A/Programmi/Anaconda/envs/NLP_2022/lib/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   <a href='file:///d%3A/Programmi/Anaconda/envs/NLP_2022/lib/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   <a href='file:///d%3A/Programmi/Anaconda/envs/NLP_2022/lib/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\Programmi\\Anaconda\\envs\\NLP_2022\\lib\\site-packages\\torch\\nn\\modules\\linear.py:103\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    <a href='file:///d%3A/Programmi/Anaconda/envs/NLP_2022/lib/site-packages/torch/nn/modules/linear.py?line=101'>102</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> <a href='file:///d%3A/Programmi/Anaconda/envs/NLP_2022/lib/site-packages/torch/nn/modules/linear.py?line=102'>103</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "iteration = 1\n",
    "\n",
    "for LEARNING_RATE in LEARNING_RATE_LIST:\n",
    "    for EMBEDDING_DIM in EMBEDDING_DIM_LIST:\n",
    "        for KERNEL_SIZE in KERNEL_SIZE_LIST:\n",
    "            for STRIDE in STRIDE_LIST:\n",
    "                for PADDING in PADDING_LIST:\n",
    "                    for DROPOUT_P in DROPOUT_P_LIST:\n",
    "\n",
    "                        # re-import the class PytorchModel\n",
    "                        # --> this is to be sure that each model is new, and not trained from the epoch of the previous one\n",
    "\n",
    "                        importlib.reload(CustomPytorchModule)\n",
    "                        PYTORCH_MODEL = CustomPytorchModule.PytorchModel\n",
    "\n",
    "                        CNN_MODEL = PYTORCH_MODEL(\n",
    "\n",
    "                            # set model and text language\n",
    "                            model_type      = \"CNN_fixed\",\n",
    "                            dataset         = dataframe,\n",
    "                            language        = \"it\",\n",
    "\n",
    "                            # set device, bacth size and epochs\n",
    "                            device          = device,\n",
    "                            batch_size      = 64,\n",
    "                            epochs          = 50,\n",
    "\n",
    "                            # set general hyperparameters\n",
    "                            learning_rate   = LEARNING_RATE,\n",
    "\n",
    "                            # set specific hyperparameters\n",
    "                            vocab_size      = COUNTS_IT,\n",
    "                            embedding_dim   = EMBEDDING_DIM,\n",
    "                            out_channels    = 1,\n",
    "                            kernel_size     = KERNEL_SIZE,\n",
    "                            stride          = STRIDE,\n",
    "                            padding         = PADDING,\n",
    "                            dropout_p       = DROPOUT_P,\n",
    "                        )\n",
    "\n",
    "\n",
    "                        # train the model\n",
    "                        CNN_MODEL.train_model()\n",
    "\n",
    "                        iteration+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "\n",
    "    iteration = 1\n",
    "\n",
    "    for LEARNING_RATE in LEARNING_RATE_LIST:\n",
    "        for EMBEDDING_DIM in EMBEDDING_DIM_LIST:\n",
    "            for KERNEL_SIZE in KERNEL_SIZE_LIST:\n",
    "                for STRIDE in STRIDE_LIST:\n",
    "                    for PADDING in PADDING_LIST:\n",
    "                        for DROPOUT_P in DROPOUT_P_LIST:\n",
    "\n",
    "                            # re-import the class PytorchModel\n",
    "                            # --> this is to be sure that each model is new, and not trained from the epoch of the previous one\n",
    "\n",
    "                            importlib.reload(CustomPytorchModule)\n",
    "                            PYTORCH_MODEL = CustomPytorchModule.PytorchModel\n",
    "\n",
    "                            CNN_MODEL = PYTORCH_MODEL(\n",
    "\n",
    "                                # set model and text language\n",
    "                                model_type      = \"CNN_fixed\",\n",
    "                                dataset         = dataframe,\n",
    "                                language        = \"pl\",\n",
    "\n",
    "                                # set device, bacth size and epochs\n",
    "                                device          = device,\n",
    "                                batch_size      = 64,\n",
    "                                epochs          = 50,\n",
    "\n",
    "                                # set general hyperparameters\n",
    "                                learning_rate   = LEARNING_RATE,\n",
    "\n",
    "                                # set specific hyperparameters\n",
    "                                vocab_size      = COUNTS_PL,\n",
    "                                embedding_dim   = EMBEDDING_DIM,\n",
    "                                out_channels    = 1,\n",
    "                                kernel_size     = KERNEL_SIZE,\n",
    "                                stride          = STRIDE,\n",
    "                                padding         = PADDING,\n",
    "                                dropout_p       = DROPOUT_P,\n",
    "                            )\n",
    "\n",
    "\n",
    "                            # train the model\n",
    "                            CNN_MODEL.train_model()\n",
    "\n",
    "                            iteration+=1\n",
    "except:\n",
    "    print(\"Upsy daisyyy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "\n",
    "    iteration = 1\n",
    "\n",
    "    for LEARNING_RATE in LEARNING_RATE_LIST:\n",
    "        for EMBEDDING_DIM in EMBEDDING_DIM_LIST:\n",
    "            for KERNEL_SIZE in KERNEL_SIZE_LIST:\n",
    "                for STRIDE in STRIDE_LIST:\n",
    "                    for PADDING in PADDING_LIST:\n",
    "                        for DROPOUT_P in DROPOUT_P_LIST:\n",
    "\n",
    "                            # re-import the class PytorchModel\n",
    "                            # --> this is to be sure that each model is new, and not trained from the epoch of the previous one\n",
    "\n",
    "                            importlib.reload(CustomPytorchModule)\n",
    "                            PYTORCH_MODEL = CustomPytorchModule.PytorchModel\n",
    "\n",
    "                            CNN_MODEL = PYTORCH_MODEL(\n",
    "\n",
    "                                # set model and text language\n",
    "                                model_type      = \"CNN_fixed\",\n",
    "                                dataset         = dataframe,\n",
    "                                language        = \"sv\",\n",
    "\n",
    "                                # set device, bacth size and epochs\n",
    "                                device          = device,\n",
    "                                batch_size      = 64,\n",
    "                                epochs          = 50,\n",
    "\n",
    "                                # set general hyperparameters\n",
    "                                learning_rate   = LEARNING_RATE,\n",
    "\n",
    "                                # set specific hyperparameters\n",
    "                                vocab_size      = COUNTS_SV,\n",
    "                                embedding_dim   = EMBEDDING_DIM,\n",
    "                                out_channels    = 1,\n",
    "                                kernel_size     = KERNEL_SIZE,\n",
    "                                stride          = STRIDE,\n",
    "                                padding         = PADDING,\n",
    "                                dropout_p       = DROPOUT_P,\n",
    "                            )\n",
    "\n",
    "\n",
    "                            # train the model\n",
    "                            CNN_MODEL.train_model()\n",
    "\n",
    "                            iteration+=1\n",
    "except:\n",
    "    print(\"Upsy daisyyy\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "455534d435f7de67bc0026f9ceba702b21954bd7ad83505586b95ef58f556ae5"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('NLP_2022')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
