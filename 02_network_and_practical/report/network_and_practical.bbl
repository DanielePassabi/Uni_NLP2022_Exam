\begin{thebibliography}{10}

\bibitem{Albawi2017UnderstandingOA}
Saad Albawi, Tareq~Abed Mohammed, and Saad Al-Zawi.
\newblock Understanding of a convolutional neural network.
\newblock {\em 2017 International Conference on Engineering and Technology
  (ICET)}, pages 1--6, 2017.

\bibitem{balakrishnan2014stemming}
Vimala Balakrishnan and Ethel Lloyd-Yemoh.
\newblock Stemming and lemmatization: a comparison of retrieval performances.
\newblock 2014.

\bibitem{cross_entropy}
Jason Brownlee.
\newblock {A Gentle Introduction to Cross-Entropy for Machine Learning}.
\newblock \\
  \url{https://machinelearningmastery.com/cross-entropy-for-machine-learning/}.
\newblock \\Accessed: 2705-2022.

\bibitem{LSTM_gentle_intro}
Jason Brownlee.
\newblock {A Gentle Introduction to Long Short-Term Memory Networks by the
  Experts}.
\newblock \\
  \url{https://machinelearningmastery.com/gentle-introduction-long-short-term-memory-networks-experts/}.
\newblock \\Accessed: 23-05-2022.

\bibitem{MaxPool_how}
Jason Brownlee.
\newblock {A Gentle Introduction to Pooling Layers for Convolutional Neural
  Networks}.
\newblock \\
  \url{https://machinelearningmastery.com/pooling-layers-for-convolutional-neural-networks/}.
\newblock \\Accessed: 27-05-2022.

\bibitem{CNN_how}
Jason Brownlee.
\newblock {How Do Convolutional Layers Work in Deep Learning Neural Networks?}
\newblock \\
  \url{https://machinelearningmastery.com/convolutional-layers-for-deep-learning-neural-networks/}.
\newblock \\Accessed: 27-05-2022.

\bibitem{cahyani2021performance}
Denis~Eka Cahyani and Irene Patasik.
\newblock Performance comparison of tf-idf and word2vec models for emotion text
  classification.
\newblock {\em Bulletin of Electrical Engineering and Informatics},
  10(5):2780--2788, 2021.

\bibitem{Chalkidis2021MultiEURLEXA}
Ilias Chalkidis, Manos Fergadiotis, and Ion Androutsopoulos.
\newblock {MultiEURLEX - A multi-lingual and multi-label legal document
  classification dataset for zero-shot cross-lingual transfer}.
\newblock In {\em EMNLP}, 2021.

\bibitem{Graves2005FramewisePC}
Alex Graves and Juergen Schmidhuber.
\newblock Framewise phoneme classification with bidirectional lstm networks.
\newblock {\em Proceedings. 2005 IEEE International Joint Conference on Neural
  Networks, 2005.}, 4:2047--2052 vol. 4, 2005.

\bibitem{IBM_NLP}
IBM.
\newblock {Natural Language Processing (NLP)}.
\newblock \\ \url{https://www.ibm.com/cloud/learn/natural-language-processing}.
\newblock \\Accessed: 21-05-2022.

\bibitem{lovins1968development}
Julie~Beth Lovins.
\newblock Development of a stemming algorithm.
\newblock {\em Mech. Transl. Comput. Linguistics}, 11(1-2):22--31, 1968.

\bibitem{nadkarni2011natural}
Prakash~M Nadkarni, Lucila Ohno-Machado, and Wendy~W Chapman.
\newblock Natural language processing: an introduction.
\newblock {\em Journal of the American Medical Informatics Association},
  18(5):544--551, 2011.

\bibitem{pytorch_dropout}
PyTorch.
\newblock {Dropout}.
\newblock \\
  \url{https://pytorch.org/docs/stable/generated/torch.nn.Dropout.html}.
\newblock \\Accessed: 24-05-2022.

\bibitem{pytorch_embedding}
PyTorch.
\newblock {Embedding}.
\newblock \\
  \url{https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html}.
\newblock \\Accessed: 24-05-2022.

\bibitem{pytorch_linear}
PyTorch.
\newblock {Linear}.
\newblock \\
  \url{https://pytorch.org/docs/stable/generated/torch.nn.Linear.html}.
\newblock \\Accessed: 24-05-2022.

\bibitem{pytorch_lstm}
PyTorch.
\newblock {LSTM}.
\newblock \\
  \url{https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html}.
\newblock \\Accessed: 24-05-2022.

\bibitem{TDS_NLP}
Towards~Data Science.
\newblock {The Importance of Natural Language Processing for Non-English
  Languages}.
\newblock \\
  \url{https://towardsdatascience.com/the-importance-of-natural-language-processing-for-non-english-languages-ada463697b9d}.
\newblock \\Accessed: 21-05-2022.

\bibitem{Zaremba2014RecurrentNN}
Wojciech Zaremba, Ilya Sutskever, and Oriol Vinyals.
\newblock Recurrent neural network regularization.
\newblock {\em ArXiv}, abs/1409.2329, 2014.

\end{thebibliography}
