\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{nadkarni2011natural}
\citation{IBM_NLP}
\citation{TDS_NLP}
\citation{Chalkidis2021MultiEURLEXA}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2}Data}{1}{section.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces MultiEURLEX Dataset - Distribution of Classes and Texts Occurrences\relax }}{2}{figure.caption.3}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:original_classes}{{1}{2}{MultiEURLEX Dataset - Distribution of Classes and Texts Occurrences\relax }{figure.caption.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Architectures}{2}{section.3}\protected@file@percent }
\newlabel{sec:architectures}{{3}{2}{Architectures}{section.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Long Short Term Memory}{2}{subsection.3.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Structure of Feedforward and Recurrent Neural Networks\relax }}{2}{figure.caption.4}\protected@file@percent }
\newlabel{figure:fnn_vs_rnn}{{2}{2}{Structure of Feedforward and Recurrent Neural Networks\relax }{figure.caption.4}{}}
\citation{LSTM_gentle_intro}
\citation{Graves2005FramewisePC}
\citation{Zaremba2014RecurrentNN}
\citation{Albawi2017UnderstandingOA}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Convolutional Neural Network}{3}{subsection.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Linear Support Vector Classifier}{4}{subsection.3.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Hyperplane in 2D case\relax }}{4}{figure.caption.5}\protected@file@percent }
\newlabel{figure:hyperplane_2d}{{3}{4}{Hyperplane in 2D case\relax }{figure.caption.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Maximum Margin Hyperplane and Support Vectors (highlighted points)\relax }}{4}{figure.caption.5}\protected@file@percent }
\newlabel{figure:max_margin_classifier}{{4}{4}{Maximum Margin Hyperplane and Support Vectors (highlighted points)\relax }{figure.caption.5}{}}
\citation{lovins1968development}
\citation{balakrishnan2014stemming}
\@writefile{toc}{\contentsline {section}{\numberline {4}Experimental Setup}{5}{section.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Data Cleaning and Preprocessing}{5}{subsection.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Feature Extraction}{5}{subsection.4.2}\protected@file@percent }
\newlabel{subsec:feature_extr}{{4.2}{5}{Feature Extraction}{subsection.4.2}{}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Total number of unique words in each language corpus\relax }}{6}{table.caption.7}\protected@file@percent }
\newlabel{table:tot_words_for_corpuses}{{1}{6}{Total number of unique words in each language corpus\relax }{table.caption.7}{}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Total number of unique words in each language corpus that appears at least 100 times\relax }}{6}{table.caption.8}\protected@file@percent }
\newlabel{table:tot_words_for_corpuses_only_common}{{2}{6}{Total number of unique words in each language corpus that appears at least 100 times\relax }{table.caption.8}{}}
\citation{pytorch_embedding}
\citation{pytorch_lstm}
\citation{pytorch_linear}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Implementing the Architectures}{7}{subsection.4.3}\protected@file@percent }
\newlabel{subsec:implementation}{{4.3}{7}{Implementing the Architectures}{subsection.4.3}{}}
\citation{pytorch_dropout}
\citation{CNN_how}
\citation{MaxPool_how}
\citation{cross_entropy}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}Training Regime}{8}{subsection.4.4}\protected@file@percent }
\newlabel{subsec:fine_tuning}{{4.4}{8}{Training Regime}{subsection.4.4}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Hyperparameters tested for LSTM networks\relax }}{9}{table.caption.16}\protected@file@percent }
\newlabel{table:LSTM_hyperparameters}{{3}{9}{Hyperparameters tested for LSTM networks\relax }{table.caption.16}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces Hyperparameters tested for Convolutional Neural Networks\relax }}{9}{table.caption.18}\protected@file@percent }
\newlabel{table:CNN_hyperparameters}{{4}{9}{Hyperparameters tested for Convolutional Neural Networks\relax }{table.caption.18}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Results}{10}{section.5}\protected@file@percent }
\newlabel{sec:results}{{5}{10}{Results}{section.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Training Times}{10}{subsection.5.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Training Times of the Architectures\relax }}{10}{figure.caption.20}\protected@file@percent }
\newlabel{fig:training_times}{{5}{10}{Training Times of the Architectures\relax }{figure.caption.20}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Training Results}{11}{subsection.5.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Best Hyperparameters, Best Epoch (when available) and Validation Accuracy for each Architecture\relax }}{11}{figure.caption.21}\protected@file@percent }
\newlabel{fig:hyperparam_epoch_res}{{6}{11}{Best Hyperparameters, Best Epoch (when available) and Validation Accuracy for each Architecture\relax }{figure.caption.21}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}Model Performances}{12}{subsection.5.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Architectures Performances on Test Set\relax }}{12}{figure.caption.22}\protected@file@percent }
\newlabel{fig:results}{{7}{12}{Architectures Performances on Test Set\relax }{figure.caption.22}{}}
\citation{cahyani2021performance}
\@writefile{toc}{\contentsline {section}{\numberline {6}Discussion}{13}{section.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}About the Results}{13}{subsection.6.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2}Ideas for Expanding the Project}{13}{subsection.6.2}\protected@file@percent }
\citation{omalley2019kerastuner}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces \relax }}{15}{figure.caption.23}\protected@file@percent }
\newlabel{figure:lstm_res}{{8}{15}{\relax }{figure.caption.23}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces \relax }}{16}{figure.caption.24}\protected@file@percent }
\newlabel{figure:cnn_res}{{9}{16}{\relax }{figure.caption.24}{}}
\bibstyle{plain}
\bibdata{biblio}
\bibcite{Albawi2017UnderstandingOA}{1}
\bibcite{balakrishnan2014stemming}{2}
\bibcite{cross_entropy}{3}
\bibcite{LSTM_gentle_intro}{4}
\bibcite{MaxPool_how}{5}
\bibcite{CNN_how}{6}
\bibcite{cahyani2021performance}{7}
\bibcite{Chalkidis2021MultiEURLEXA}{8}
\bibcite{Graves2005FramewisePC}{9}
\bibcite{IBM_NLP}{10}
\bibcite{lovins1968development}{11}
\bibcite{nadkarni2011natural}{12}
\bibcite{omalley2019kerastuner}{13}
\bibcite{pytorch_dropout}{14}
\bibcite{pytorch_embedding}{15}
\@writefile{toc}{\contentsline {section}{References}{17}{figure.caption.24}\protected@file@percent }
\bibcite{pytorch_linear}{16}
\bibcite{pytorch_lstm}{17}
\bibcite{TDS_NLP}{18}
\bibcite{Zaremba2014RecurrentNN}{19}
