\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{nadkarni2011natural}
\citation{IBM_NLP}
\citation{TDS_NLP}
\citation{Chalkidis2021MultiEURLEXA}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2}Data}{1}{section.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces MultiEURLEX Dataset - Distribution of Classes and Texts Occurrences\relax }}{2}{figure.caption.3}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:original_classes}{{1}{2}{MultiEURLEX Dataset - Distribution of Classes and Texts Occurrences\relax }{figure.caption.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Architectures}{2}{section.3}\protected@file@percent }
\newlabel{sec:architectures}{{3}{2}{Architectures}{section.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Long Short Term Memory}{2}{subsection.3.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Structure of Feedforward and Recurrent Neural Networks\relax }}{2}{figure.caption.4}\protected@file@percent }
\newlabel{figure:fnn_vs_rnn}{{2}{2}{Structure of Feedforward and Recurrent Neural Networks\relax }{figure.caption.4}{}}
\citation{LSTM_gentle_intro}
\citation{Graves2005FramewisePC}
\citation{Zaremba2014RecurrentNN}
\citation{Albawi2017UnderstandingOA}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Convolutional Neural Network}{3}{subsection.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Linear Support Vector Classifier}{4}{subsection.3.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Hyperplane in 2D case\relax }}{4}{figure.caption.5}\protected@file@percent }
\newlabel{figure:hyperplane_2d}{{3}{4}{Hyperplane in 2D case\relax }{figure.caption.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Maximum Margin Hyperplane and Support Vectors (highlighted points)\relax }}{4}{figure.caption.5}\protected@file@percent }
\newlabel{figure:max_margin_classifier}{{4}{4}{Maximum Margin Hyperplane and Support Vectors (highlighted points)\relax }{figure.caption.5}{}}
\citation{lovins1968development}
\citation{balakrishnan2014stemming}
\@writefile{toc}{\contentsline {section}{\numberline {4}Experimental Setup}{5}{section.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Data Cleaning and Preprocessing}{5}{subsection.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Feature Extraction}{5}{subsection.4.2}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Total number of different words in each language corpus.\relax }}{6}{table.caption.7}\protected@file@percent }
\newlabel{table:tot_words_for_corpuses}{{1}{6}{Total number of different words in each language corpus.\relax }{table.caption.7}{}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Total number of different words in each language corpus that appears at least 100 times.\relax }}{6}{table.caption.8}\protected@file@percent }
\newlabel{table:tot_words_for_corpuses_only_common}{{2}{6}{Total number of different words in each language corpus that appears at least 100 times.\relax }{table.caption.8}{}}
\citation{pytorch_embedding}
\citation{pytorch_lstm}
\citation{pytorch_linear}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Implementing the Architectures}{7}{subsection.4.3}\protected@file@percent }
\citation{pytorch_dropout}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}Training Regime}{8}{subsection.4.4}\protected@file@percent }
\newlabel{subsec:fine_tuning}{{4.4}{8}{Training Regime}{subsection.4.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Results}{10}{section.5}\protected@file@percent }
\newlabel{sec:results}{{5}{10}{Results}{section.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces \relax }}{11}{figure.caption.16}\protected@file@percent }
\newlabel{figure:lstm_res}{{5}{11}{\relax }{figure.caption.16}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Discussion}{12}{section.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}About the Results}{12}{subsection.6.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2}Ideas for Expanding the Project}{12}{subsection.6.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{Bibliography}{12}{subsection.6.2}\protected@file@percent }
\bibstyle{plain}
\bibdata{biblio}
\bibcite{Albawi2017UnderstandingOA}{1}
\bibcite{balakrishnan2014stemming}{2}
\bibcite{LSTM_gentle_intro}{3}
\bibcite{Chalkidis2021MultiEURLEXA}{4}
\bibcite{Graves2005FramewisePC}{5}
\bibcite{IBM_NLP}{6}
\bibcite{lovins1968development}{7}
\bibcite{nadkarni2011natural}{8}
\bibcite{pytorch_dropout}{9}
\bibcite{pytorch_embedding}{10}
\bibcite{pytorch_linear}{11}
\bibcite{pytorch_lstm}{12}
\bibcite{TDS_NLP}{13}
\bibcite{Zaremba2014RecurrentNN}{14}
